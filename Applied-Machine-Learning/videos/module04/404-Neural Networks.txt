In this part of the course, you'll get an introduction to
the basics of neural networks. Which are a broad family of algorithms
that have formed the basis for the recent resurgence in the computational
field called deep learning. Early work on neural networks
actually began in the 1950s and 60s. And just recently,
has experienced a resurgence of interest, as deep learning has achieved
impressive state-of-the-art results. On specific tasks that range from
object classification in images, to fast accurate machine translation,
to gameplay. The topic of neural networks
requires its own course. And indeed,
if you're interested in more depth, you can check out the excellent
course on Coursera. Called Neural Networks for Machine
Learning, by a pioneer in this area, Professor Jeff Hinton. Here, we'll provide an introduction
to the basic concepts and algorithms that are foundation
of neural networks. And of the much more sophisticated
deep learning methods in use today. You'll learn about some basic models
called multi-layer perceptrons, supported by scikit-learn, that can be
used for classification and regression. Let's start by briefly reviewing simpler
methods we have already seen for regression and classification. Linear regression and logistic regression,
which we show graphically here. Linear regression predicts
a continuous output, y hat, shown as the box on the right. As a function as the sum
of the input variables xi, shown in the boxes on the left. Each weighted by
a corresponding coefficient, wi hat, plus an intercept or
bias term, b hat. We saw how various methods
like ordinary least squares, ridge regression or lasso regression. Could be used to estimate these
model coefficients, wi hat and b hat, shown above the arrows in
the diagram, from training data. Logistic regression takes
this one step further, by running the output of the linear
function of the input variables, xi. Through an additional nonlinear function,
the logistic function. Represented by the new box in the middle
of the diagram, to produce the output, y. Which, because of the logistic function, is now constrained to lie between zero and
one. We use logistical regression for
binary classification. Since we can interpret
y as the probability that a given input data instance
belongs to the positive class, in a two-class binary
classification scenario. Here's an example of
a simple neural network for regression, called
a multi-layer perceptron. Which I will sometimes abbreviate by MLP. These are also known as
feed-forward neural networks. MLPs take this idea of computing
weighted sums of the input features, like we saw in logistic regression. But it takes it a step
beyond logistic regression, by adding an additional processing
step called a hidden layer. Represented by this additional set of
boxes, h0, h1, and h2 in the diagram. These boxes, within the hidden layer,
are called hidden units. And each hidden unit in the hidden
layer computes a nonlinear function of the weighted sums of the input features. Resulting in intermediate output values,
v0, v1, v2. Then the MLP computes a weighted
sum of these hidden unit outputs, to form the final output value, Y hat. This nonlinear function that
the hidden unit applies. is called the activation function. In this example, your activation function
is the hyperbolic tangent function, which is related to the logistic function. You can see that the result of adding this
additional hidden layer processing step to the prediction model,
is a formula for y hat. That is already more involved than
the one for logistic regression. Now predicting y involves computing
a different initial weighted sum of the input feature values for
each hidden unit. Which applies a nonlinear
activation function. And then all of these nonlinear outputs
are combined, using another weighted sum, to produce y. In particular, there's one weight
between each input and each hidden unit. And one weight between each hidden
unit and the output variable. In fact, this addition and combination
of non-linear activation functions. Allows multi-layer perceptrons
to learn more complex functions. Than is possible with a simple linear or
logistic function. This additional expressive power enables
neural networks to perform more accurate prediction. When the relationship between the input
and output is itself complex. Of course, this complexity also means
that there are a lot more weights, model coefficients,
to estimate in the training phase. Which means that both more training data
and more computation are typically needed to learn in a neural network,
compared to a linear model. As an aside, there are a number of choices
for the activation function in a neural network, that gets
applied in hidden units. Here, the plot shows the input value
coming into the activation function, from the previous layer's
inputs on the x-axis. And the y-axis shows the resulting
output value for the function. This code to plot this example is
available in the accompanying notebook. The three main activation functions
we'll compare later in this lecture are the hyperbolic tangent. That's the S-shaped function in green. The rectified linear unit function,
which I'll abbreviate to relu, shown as the piecewise
linear function in blue. And the familiar logistic function,
which is shown in red. The relu activation function is
the default activation function for neural networks in scikit-learn. It maps any negative input values to zero. The hyperbolic tangent function,
or tanh function. Maps large positive input values
to outputs very close to one. And large negative input values,
to outputs very close to negative one. These differences in the activation
function can have some effect on the shape of regression prediction plots. Or classification decision boundaries
that neural networks learn. In general, we'll be using
either the hyperbolic tangent or the relu function as our
default activation function. Since these perform well for
most applications. Let's take a look at how we use
neural networks in scikit-learn for classification. Using the more complex synthetic
binary classification data set. To use a neural network classifier, you import the MLPClassifier class from
the sklearn.neural_network module. This code example shows the classifier
being fit to the training data, using a single hidden layer. With three different numbers
of hidden units in the layer, 1 unit, 10 units and 100 units. As with all other classification
types we've seen, you can create the classifier objects
with the appropriate parameters. And call the fit method
on the training data. Here, the main parameter for a neural network classifier is this
parameter, hidden_layer_sizes. This parameter is a list,
with one element for each hidden layer, that gives the number of hidden
units to use for that layer. So here we're passing a list
with a single element. Meaning we want one hidden layer, using
the number in the variable called units. By default, if you don't specify
the hidden_layer_sizes parameter, scikit-learn will create a single
hidden layer with 100 hidden units. While a setting of 10 may work well for
simple data sets, like the one we use as examples here. For really complex data sets, the number
of hidden units could be in the thousands. It's also possible, as we'll see shortly, to create an MLP with more
than one hidden layer. By passing a hidden_layer_sizes
parameter with multiple entries. I want to also note the use of this
extra parameter, called solver. Which specifies the algorithm to use for
learning the weights of the network. Here, we're using the lbfgs algorithm. We'll discuss the solver parameter setting
further, at the end of this lecture. Also note that we're passing
in a random_state parameter, when creating the MLPClassifier object. Like we did for
the train-test split function. And we happened to set this random state
parameter to a fixed value of zero. This is because for neural networks,
their weights are initialized randomly, which can affect the model
that is learned. Because of this, even without changing
the key parameters on the same data set. The same neural network algorithm
might learn two different models. Depending on the value of the internal
random seed that is chosen. So by always setting the same value for the random seed used to
initialize the weights. We can assure the results
will always be the same, for everyone using these examples. This graphic plots the results
of running this code. To show how the number of hidden
units in a single layer in the neural network affects the model complexity for
classification. With a single hidden unit, the model is mathematically
equivalent to logistic regression. We see the classifier returns the familiar
simple linear decision boundary between the two classes. The training set score's low, and
the test score is not much better, so this network model is under-fitting. With ten hidden units, we can see that
the MLPClassifier is able to learn a more complete decision boundary. That captures more of the nonlinear,
cluster-oriented structure in the data, though the test set accuracy is still low. With 100 hidden units, the decision
boundary is even more detailed. And achieves much better accuracy,
on both the training and the test sets. Here's a graphical depiction of
a multi-layer perceptron with two hidden layers. Adding the second hidden layer further
increases the complexity of functions that the neural network can learn,
from more complex data sets. Taking this complexity further,
large architectures of neural networks, with many stages of computation, are why
deep learning methods are called deep. And we'll summarize deep learning,
in an upcoming lecture for this week. Here is an example in the notebook,
showing how we create a two-layer MLP, with 10 hidden units in each layer. We just set
the hidden_layer_sizes parameter, when creating the MLPClassifier,
to a two-element list. Indicating ten units,
in each of the two hidden layers. You can see the result of of
adding the second hidden layer, on the classification
problem we saw earlier. On the left is the original MLP,
with one hidden layer of ten units. And on the right is the same data set, using a new MLP with two hidden
layers of ten units each. You can see the MLP with two hidden layers
learned a more complex decision boundary. And achieved, in this case,
a much better fit on the training data, and slightly better
accuracy on the test data. Once we start adding more hidden layers,
with lots of hidden units. You can see that the number of weights,
or model coefficients, to estimate for a neural network can increase rapidly. So that more complex neural networks
could have many thousands of weights to estimate. We can control this model complexity, just
as we did with ridge and lasso regression. By adding an L2 regularization
penalty on the weights. Remember that L2 regularization penalizes
models that have a large sum of squares of all the weight values. With the effect being, that the neural network prefers models
with more weights shrunk close to zero. The regularization parameter for
MLPs is called alpha, like with the linear regression models. And in scikit-learn,
it's set to a small value by default, like 0.0001,
that gives a little bit of regularization. This code example shows
the effects of changing alpha for a larger MLP,
with 2 hidden layers of 100 nodes each. From a small value of 0.01,
to a larger value of 5.0. For variety here, we're also setting the activation function
to use the hyperbolic tangent function. Here's the graphical output
of this notebook code. You can see the effect of increasing
regularization with increasing alpha. In the left plot, when alpha is small, the decision boundaries are much
more complex and variable. And the classifier's over-fitting, as we can see from the very high
training set score, and low test score. On the other hand, the right plot uses the
largest value of alpha here, alpha 5.0. And that setting results in much
smoother decision boundaries, while still capturing the global
structure of the data. And this increased simplicity allows
it to generalize much better, and not over-fit to the training set. And this is evident from the much
higher test score, in this case. As with other supervised learning models,
like regularized regression and support vector machines. It can be critical, when using neural networks,
to properly normalize the input features. Let's apply the multi-layer perceptron
to the breast cancer data set. And notice that we first
apply the MinMaxScaler, to pre-process the input features. Here we'll combine a more complex network,
using 2 hidden layers with 100 units each. With a higher regularization
setting of alpha at 5.0, and using the lgbfs solver again. You can see, that with this multi-layer
perceptron, both the training and test set accuracy are among the highest
we have obtained on this data set. Like many of the other supervised
learning methods we've seen, you can also use multi-layer perceptrons
for regression, as well as classification. We're including MLP regression here,
as an example, for two reasons. First, because MLP
regression may be useful for some regression problems on its own. But more generally, because some deep
learning problems are regression problems. And so, as with classification, using
multi-layer perceptrons is a good starting point to learn about the more
complex architectures used for regression in deep learning. Here's the example of a simple MLP
regression model, in our notebook. You use the multi-layer
perceptron regressor by importing the MLPRegressor class from
the sklearn.neural_network module, and then creating the MLPRegressor object. When creating the object here, we're
setting the number of hidden layers and units within each hidden layer. Using the same hidden_layer_sizes
parameter that we used for classification. This example uses two hidden layers,
with 100 hidden nodes each. This notebook code has a loop that
cycles through different settings of the activation function parameter, and
the alpha parameter for L2 regularization. Here we've included regression
results that use, in the top row, the hyperbolic tangent
activation function. And in the bottom row,
the relu activation function. You can see the smoothness of the
activation function somewhat influences the smoothness of the corresponding
regression results. Along the columns, the plots also show the
effect of using different alpha settings, to increase the amount of L2
regularization from left to right. Again, as with classification, the effect of increasing the amount of
L2 regularization, by increasing alpha. Is to constrain the regression to use
simpler and simpler models, with fewer and fewer large weights. You can see this effect for
both activation functions, in the top and bottom rows. The regression line on the left has
higher variance than the much smoother, regularized model on the right. On the positive side, beyond these
simple examples we've shown here. Neural networks form the basis of
advanced learning architectures. That capture complex features, and
give state-of-the-art performance on an increasingly wide variety
of difficult learning tasks. From world-championship play for
the game of Go, to detailed and robust recognition of objects and images. However, with this increased power,
come increased costs. This larger and more complex models
typically require significant volumes of data, computation, and
training time to learn. In addition, careful pre-processing of the
input data is needed, to help ensure fast, stable, meaningful solutions to
finding the optimal set of weights. In general,
neural networks are a good choice, when the features are of similar types. For example,
all derived from the pixels of an image. And less of a good choice, when
the features are of very different types. Finally, let's review the key parameters
for the multi-layer perceptron in scikit-learn, that can be used
to control model complexity. The main way to control model
complexity for the MLP, is to control the hidden unit size and
structure. Using the hidden_layers_sizes parameter
that controls the number of hidden layers, and the number of units within each layer. Alpha controls the amount of
regularization that helps constrain the complexity of the model, by constraining the magnitude
of model weights. Finally, you can experiment with at
least three different choices for the nonlinear activation function,
by using the activation parameter. Earlier, we saw the solver parameter, for specifying the algorithm that
learns the network weights. Solver is the algorithm that actually
does the numerical work of finding the optimal weights. And one intuitive way of
visualizing this process. Is that all of the solver algorithms
have to do a kind of hill-climbing in a very bumpy landscape,
with lots of local minima. Where each local minimum corresponds
to a locally optimal set of weights. That is, a choice of weight setting that's
better than any nearby choices of weights. So across this whole landscape
of very bumpy local minima. Some will have higher validation scores on
the test data, and some will have lower. So depending on the initial random
initialization of the weights. And the nature of the trajectory
in the search path that a solver takes through
this bumpy landscape. The solver can end up at
different local minima, which can have different
validation scores. The default solver, adam,
tends to be both efficient and effective on large data sets,
with thousands of training examples. For small data sets, like many of
the ones we use in these examples, the lbfgs solver tends to be faster,
and find more effective weights. You can find further details on these more
advanced settings in the documentation for scikit-learn.